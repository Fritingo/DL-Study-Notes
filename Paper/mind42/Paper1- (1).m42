{"id":"85448126-3313-41c2-ac9a-467f7b9fc0b1","revision":"117332442","root":{"id":"rootNode","children":[{"id":"0887bb56-2525-4ed1-8be8-d63dcf643969","children":[{"id":"27fa40ff-a554-408d-8bc1-6da34a7e40eb","children":[],"attributes":{"type":"container","text":"大數據 (big data) 來臨，每天獲取的資料量以爆炸性的速度成長","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543202585925}}],"attributes":{"type":"container","text":"研究之背景","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543197912124}},{"id":"321e0f41-9c09-4965-85e7-fe11e21c2eed","children":[{"id":"8e598df7-a7ad-45aa-82a6-75d02205feac","children":[],"attributes":{"type":"container","text":"分析解釋資訊，協助使用者更快速且精準地找出所需資訊","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543202616177}}],"attributes":{"type":"container","text":"動機與目的","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543197935606}},{"id":"bcd2cd43-608e-4c1f-83b7-261e87527dcb","children":[{"id":"e438cddf-47ab-4dce-8482-2b7f73632c56","children":[],"attributes":{"type":"container","text":"https://hdl.handle.net/11296/z4x7w9","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{"url":"https://hdl.handle.net/11296/z4x7w9"},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543200040651}}],"attributes":{"type":"container","text":"Paper出處","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543200040651}},{"id":"f1921d46-a3d8-4745-8ed0-6ba68f64b0df","children":[{"id":"33845228-828e-4e5d-82f1-656df4aed3f5","children":[],"attributes":{"type":"image","text":"","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/system.png","width":"300","height":"219"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545139408270}}],"attributes":{"type":"container","text":"系統架構","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545137295481}},{"id":"81c20885-9ed9-452a-8cf9-aa0ec6e86b74","children":[{"id":"2d5c8ce4-e753-470c-8e66-5d53c98442d9","children":[{"id":"e41a9f36-5692-4f2c-891b-356ec67a6be6","children":[{"id":"6227429e-1aed-43c9-8e92-12182c0dd8f8","children":[],"attributes":{"type":"image","text":"","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/nerve-cell.jpeg","width":"300","height":"190"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809327636}}],"attributes":{"type":"container","text":"概念是源自於生物神經系統,利用機器模擬生<br>物神經的學習方式,擁有學習能力","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199654048}},{"id":"be07f778-18d4-4f8e-8e6f-9bb34b500459","children":[{"id":"42dd87a5-a3d4-46dc-803c-8535d5bcda03","children":[],"attributes":{"type":"image","text":"","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/mp_model.png","width":"300","height":"165"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809322725}}],"attributes":{"type":"container","text":"1943 年依照生物的神經模型,<br>以數學描述的方式提出了 M-P 模型 (McCulloch-Pitts Model)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543204765481}},{"id":"596ca592-cbc6-4a73-8bee-ab06b2a10cd1","children":[],"attributes":{"type":"container","text":"1949 年 Hebbian 學習定律,當神經元 A 一直重複且持續激發神經元 B,則兩個神經元之間的連結會被強化,使神經元 A 能更輕易的激發神經元 B","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205020822}},{"id":"346026b8-4a8e-4a1c-8e8f-3ef3cdbbf0cc","children":[],"attributes":{"type":"container","text":"1957 年結合 M-P 模型以及 Hebb 的學習理論,提出一種前饋式 (feed-forward) 神經網路模型—感知機 (Perceptron)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205081060}},{"id":"8a82a990-ccb0-4805-831b-6f49918e2b64","children":[],"attributes":{"type":"container","text":"1969 年, Seymour Papert 與 Marvin Minsky 在《Perceptrons》書中證明感知機模型僅能處理線性分割問題","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205045037}},{"id":"c05b717e-df5d-478b-895c-76c2a15e36f4","children":[],"attributes":{"type":"container","text":"1986 年 David E. Rumelhart 等人提出倒傳遞 (Back-propagation, BP) 演算法","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205064036}},{"id":"ef493758-195b-4a1b-8233-73219346941e","children":[],"attributes":{"type":"container","text":"1987 年由 F. Rosenblatt 等人將感知機模型加入隱藏層 (Hidden layer),結合倒傳遞演算法,發展出多層感知機 (MultilayerPerceptron, MLP)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205112932}}],"attributes":{"type":"container","text":"類神經網路發展史","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199637099}},{"id":"74e2482c-b8b7-437d-8cc9-070f14e37204","children":[{"id":"d0a93aef-7384-41fd-878a-0cdde787d376","children":[],"attributes":{"type":"container","text":"資每筆資料皆有相對應的標籤 (Label)，使輸出分類更接近資料標籤的期望輸出","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198917551}},{"id":"6fde218a-412f-4d79-8aee-7e32114f65b8","children":[{"id":"fc38fd34-a6b8-4492-88ba-baa96b18c76f","children":[],"attributes":{"type":"container","text":"可以依照訓練的結果對新的資料做出正確的判斷","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199030641}}],"attributes":{"type":"container","text":"優點","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198995500}},{"id":"0a9b2a1d-d793-402a-83d1-c5eb0cff8f7d","children":[{"id":"e33fbafd-d18e-4413-8d24-264d3696fcb6","children":[],"attributes":{"type":"container","text":"需要大量的資料","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199085249}}],"attributes":{"type":"container","text":"缺點","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199052957}},{"id":"db6f0767-d6d2-4168-82c6-9a6eb0007c95","children":[{"id":"6b50c619-6ad7-4852-82e9-2c0ce518013e","children":[],"attributes":{"type":"container","text":"support vector machine, SVM","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198818501}},{"id":"789b0ec7-ddfc-46e6-8243-a954a45545d9","children":[{"id":"50cdd2ef-92ed-4c69-88e7-09e63dd4e9c8","children":[],"attributes":{"type":"image","text":"","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/MLP.png","width":"300","height":"230"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809333482}},{"id":"617db85b-4a02-45ea-8b30-804362adc63d","children":[{"id":"7791e01c-bc06-4792-8a89-338ac14b2d20","children":[],"attributes":{"type":"container","text":"前饋階段 (Forward-propagation):資料由輸入層傳入網路,計算輸入值與權重經過<br>非線型函數轉換後所得到的輸出值,最後計算每一神經元所對應的網路輸出值及其誤差函數","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543803889523}},{"id":"646f49ef-35aa-415a-80db-ecbdb074f7e1","children":[],"attributes":{"type":"container","text":"倒傳遞階段 (Back-propagation):根據前饋階段所求得的誤差函數,由最後一層輸出<br>層開始往回傳遞,並利用梯度下降法進行權重修正","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543803909788}}],"attributes":{"type":"container","text":"含有隱藏層的前饋神經網路,包含輸入層(Input Layer)、輸出層 (Output Layer) 以及一個或多個的隱藏層 (Hidden Layer), 每個神<br>經元的輸出端都包含一個非線型函數","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543803738356}}],"attributes":{"type":"container","text":"Multi-layer perceptrons","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543205168161}},{"id":"335798e6-7b0e-4210-8baf-f8dd1fe3ff86","children":[{"id":"7057a632-3fc6-41d8-809b-c413716b361a","children":[],"attributes":{"type":"image","text":"","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/CNN.png","width":"300","height":"95"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543810481799}},{"id":"6b79a0c9-fd8d-4950-8656-95d1e8b30480","children":[{"id":"d812a82a-6aa0-4afd-8937-53c7b00d8edc","children":[{"id":"76f190ee-9b83-4d4c-80b9-d0261a335f42","children":[],"attributes":{"type":"container","text":"目的是偵測形狀的邊、角，也有去除噪音(Noise)及銳化(Sharpen)的效果，萃取這些特徵當作辨識的依據，這也克服了迴歸(Regression)會受『異常點』(Outliers)嚴重影響推測結果的缺點","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809726062}}],"attributes":{"type":"image","text":"輸入影像大小為 M × N,以隨機的方式初始化網路中的卷積核 (kernel), w k 為卷積層中<br>第k個卷積核,b 為閥值 (bias) , y k 則為卷積層的輸出,之後透過移動卷積核的方式掃<br>過整個輸入影像,以點對點相乘相加的方式計算輸出,為了保持影像輸入與輸出的大小<br>不變,通常會在影像周圍補 0 (zero padding)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/Convolution.png","width":"300","height":"189"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543810538852}},{"id":"20bfb5b3-a658-45a2-86d2-96b6206dc6c7","children":[{"id":"09acd9fb-a529-4aa6-8ce8-65b8661f30e4","children":[],"attributes":{"type":"container","text":"目的是引入不變性 (invariance) 防止網路發生過度擬合 (overfitting),以及對資料進行降採樣 (Downsampling) 降低計算複雜度","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809747726}}],"attributes":{"type":"image","text":"假設 Pooling Window size 為3 × 3,因此會在3 × 3<br>的區域內找出最大值或是計算平均值來當成 Max pooling 與 Mean pooling 的輸出,之後<br>再根據步長 (step) 移動 Pooling Window,一直重複直到整個輸入特徵都被掃過","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/Pooling.png","width":"300","height":"168"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543810590600}},{"id":"7dea4aff-2b48-44be-8b27-328518af61ae","children":[{"id":"372cc6ef-cba5-415b-814a-4f62a46413e5","children":[],"attributes":{"type":"container","text":"目的是資料分類","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543810124640}}],"attributes":{"type":"container","text":"所有特徵會依序展開成一維資料,輸入全連接層 (Fully Connective Layer),結<br>合 Softmax 函數計算每個輸出類別相對應的機率值,做法與多層感知機相似","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809928613}}],"attributes":{"type":"container","text":"由卷積層 (Convolutional Layer) 、池化層 (Pooling Layer) 與全連接層 (Fully Connective Layer) ,並且在經過卷積層與最後的全連接層後分別加入不同<br>的活化函數 (activation function)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543809255922}}],"attributes":{"type":"container","text":"卷積神經網路","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543806511617}},{"id":"c04d6386-eecd-45d7-8731-7e30b5714c9d","children":[{"id":"3ed0dbbd-f807-4c1b-8aff-d101fb1e657a","children":[{"id":"85d9f171-1b0a-46cf-8baf-7670fc020178","children":[],"attributes":{"type":"image","text":"輸出的結果會回傳回輸入端,因此網路會因為輸入不同產生不同<br>的回饋,經過多次迭代,修正網路權重,直到網路收斂","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/RNN2.png","width":"300","height":"174"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544005742044}}],"attributes":{"type":"image","text":"不同於傳統的神經網路模型,為了預測下一個時間點的輸出,遞歸神經網路不僅利<br>用當前的輸入,並加入了上個時間點的訊息用於當前的輸出計算","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/RNN.png","width":"300","height":"118"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544005700716}},{"id":"bb973e81-ba68-46a7-8233-62190fe84ad0","children":[],"attributes":{"type":"container","text":"自然語言 (Natural Language Processing, NLP)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544004927819}},{"id":"4a77619c-c143-4818-8b01-3cac198e6491","children":[{"id":"58df8383-f337-4f28-81d2-5c1513525cac","children":[],"attributes":{"type":"image","text":"多了可以控制訊息的儲存、輸入以及輸出,並且判斷何時可以讀取、儲存或是遺忘訊息，透過網路訓練對權重進行調整,使各個控制單元透過倒傳遞、梯度<br>下降等方式,學習何時允許訊息輸入,如何輸出,或是訊息是否需要被儲存","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/LATM.png","width":"300","height":"157"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544005784057}}],"attributes":{"type":"container","text":"長短期記憶模型(Long short -Term Memory, LSTM)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544005158640}}],"attributes":{"type":"container","text":"遞歸神經網路","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1544004417040}}],"attributes":{"type":"container","text":"例如","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198814466}}],"attributes":{"type":"container","text":"Supervised learning","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198570623}},{"id":"3d7bbbab-0556-4237-8929-c1f5d6259de1","children":[{"id":"22560058-2e1f-48e1-8ef9-c02dd2d719bd","children":[],"attributes":{"type":"container","text":"資料不需要標籤，利用資料間的相似性進行資料分群","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198959805}},{"id":"2f923739-11cc-4615-8afb-2c2b11c65f18","children":[{"id":"2e511771-4bde-4661-8667-af5d6cf8ab66","children":[],"attributes":{"type":"container","text":"資料無需含有標籤，節省了人力資料標注","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199186042}}],"attributes":{"type":"container","text":"優點","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199107810}},{"id":"e092648f-3afd-4166-8655-348c02b59357","children":[{"id":"04fa596b-93f6-4ad0-816e-f14dcdfe78b3","children":[],"attributes":{"type":"container","text":"無法得到監督式學習一樣完美的正確率","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199216817}}],"attributes":{"type":"container","text":"缺點","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199201654}},{"id":"8aa48db2-1d1a-46d9-829c-8857fd01a34a","children":[{"id":"1bb90db1-645b-4df4-89f1-2a794ddae092","children":[],"attributes":{"type":"container","text":"Generative Adversarial Network, GAN","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199239204}}],"attributes":{"type":"container","text":"例如","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543199231060}}],"attributes":{"type":"container","text":"Unsupervised learning","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198577945}}],"attributes":{"type":"container","text":"類神經網路","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543197954233}},{"id":"76a3bfc2-3ca8-40f0-841d-4efff30d4c16","children":[{"id":"fe6168cd-483d-4719-8033-72e3bff6e029","children":[{"id":"5fcfbf52-c75b-4135-866a-c9702c0330de","children":[],"attributes":{"type":"image","text":"利用 CNN 將影片中所有的 frames 做特徵提取,經過 mean pooling 後將特徵輸入 LSTM<br>decoder 生成文字","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/video2word.png","width":"300","height":"205"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545139369488}},{"id":"3d4d7974-1fc5-43f9-8af4-fe0cc7ee4a23","children":[],"attributes":{"type":"image","text":"經改良成S2VT 網路將影片中的每個 frames 都輸入 LSTM encoder 中進行編碼,之後再送入 decoder<br>中來產生文字描述","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/S2VT.png","width":"300","height":"119"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545139241552}}],"attributes":{"type":"container","text":"影像","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198306469}},{"id":"e358e9f1-25f3-460d-8045-b29dd4b3ae9e","children":[{"id":"0c8a6084-0414-4922-83eb-7438a82e4d28","children":[],"attributes":{"type":"image","text":"前處理階段 (Pre-processing Stage)使用短時距傅立葉轉換、訓練階段<br>(Training Stage)使用非對稱摺機神經網路 ，測試分類階段 (Testing and Classification Stage)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":{"src":"https://raw.githubusercontent.com/cbc106013/DL-Study-Notes/master/Paper/pictures/%E7%B5%90%E5%90%88%E5%BD%B1%E5%83%8F%E8%88%87%E9%9F%B3%E8%A8%8A%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%B9%8B%E5%BD%B1%E7%89%87%E6%8F%8F%E8%BF%B0%E6%8A%80%E8%A1%93/voice_model.png","width":"300","height":"188"},"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545139312423}},{"id":"b83e9f4f-1b71-47dd-8e56-ce271ea9dc55","children":[],"attributes":{"type":"container","text":"梅爾倒頻譜係數 ","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545137677714}}],"attributes":{"type":"container","text":"聲音","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198322940}},{"id":"b7b788e7-0f53-4aa8-895a-757571693fea","children":[{"id":"e0d1245a-d00a-4a64-8aa9-980b968889be","children":[],"attributes":{"type":"container","text":"神經網路語言模型 (Neural Network Language Model, NNLM)","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1545136404015}}],"attributes":{"type":"container","text":"語意特徵提取","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198334144}}],"attributes":{"type":"container","text":"影片描述架構","font":{"color":"inherit","size":"default","bold":"default","italic":"default","underlined":"default"},"icon":"","links":{},"note":"","todo":[],"image":null,"lastEditor":"333f09af-1139-44a2-94e3-1ed325925576","lastEdit":1543198264113}}],"attributes":{"type":"rootnode","text":"Paper報告1-結合影像與音訊深度學習之影片描述技術"}},"version":3}